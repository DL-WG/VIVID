# VIVID


## About the project
We have developed a new method for variational data assimilation called VIVID, which incorporates a deep learning inverse operator into the assimilation objective function. This technique utilizes Voronoi-tessellation and convolutional neural networks to effectively handle sparse, unstructured, and time-varying sensor data. By incorporating the DL inverse operator, VIVID establishes a direct connection between observation and state space, which minimizes the number of steps required for data assimilation. The numerical experiments are made with a 2D shallow code provided in this reporsitory. 

![flowchart_DA](https://user-images.githubusercontent.com/28357071/229172089-d5a09e5d-f708-4006-ba98-3a10fc3442bf.PNG)

## Getting Started

*   Programming language: Python (3.5 or higher)


### Software requirement

| Package Requirement                        |
|--------------------------------------------|
| os                                         |
| sympy                                      |
| numpy                                      |
| pandas                                     |
| math                                       |
| matplotlib                                 |
| ADAO (9.10.0)                              |
| Tensorflow (2.3.0 or higher)               |
| Keras (2.4.0 or higher)                    |

![alt text](http://url/to/img.png)

## Dataset 
The experimental data are generated by the shallow_water.py file

4 simulations (each of 10000 time steps) are used as training set while one simulation is used to test the performance of the proposed algorithm

Training data parameters, (hp, rw): (0.1, 4), (0.15, 4), (0.1, 5), (0.15, 5)
Test data parameters, (hp, rw): (0.2, 6)
 
## Symbolic calculation in a simple scalar case
The symbolic calculation of the posterior variance in a simple scalar case using sympy is provided in scalar_case.py

## VCNN preprocessing and training
The preprocessing of the observations through Voronoi tessellation is presented in voronoi_preprocessing.py

The traning of VCNN is presented in VCNN_training.py

## data and trained model
We also provided trained VCNN model and the test data in case you want to only perform VIVID without retraining VCNN
